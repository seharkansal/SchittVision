{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seharkansal/SchittVision/blob/main/emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKODo0yVSxJG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GNFh6CzSxJN"
      },
      "outputs": [],
      "source": [
        "txt_file_path = './datasets/emotions_dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNwX5TB6SxJO"
      },
      "outputs": [],
      "source": [
        "# Open the txt file and read the content\n",
        "with open(txt_file_path, 'r') as file:\n",
        "    lines = file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiBwyj4vSxJP"
      },
      "outputs": [],
      "source": [
        "# Split the lines into text and emotion based on the delimiter ';'\n",
        "data = [line.strip().split(',') for line in lines]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agb0tH7VSxJQ",
        "outputId": "73717d66-eb85-429f-e961-4db5f1a7f365"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>i just had a very brief time in the beanbag an...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>i am now turning and i feel pathetic that i am...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>i feel strong and good overall</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>i feel like this was such a rude comment and i...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  Emotion\n",
              "0                                i didnt feel humiliated  sadness\n",
              "1      i can go from feeling so hopeless to so damned...  sadness\n",
              "2       im grabbing a minute to post i feel greedy wrong    anger\n",
              "3      i am ever feeling nostalgic about the fireplac...     love\n",
              "4                                   i am feeling grouchy    anger\n",
              "...                                                  ...      ...\n",
              "15995  i just had a very brief time in the beanbag an...  sadness\n",
              "15996  i am now turning and i feel pathetic that i am...  sadness\n",
              "15997                     i feel strong and good overall      joy\n",
              "15998  i feel like this was such a rude comment and i...    anger\n",
              "15999  i know a lot but i feel so stupid because i ca...  sadness\n",
              "\n",
              "[16000 rows x 2 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a DataFrame from the data\n",
        "df = pd.DataFrame(data, columns=['Text', 'Emotion'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5ZYEo7FSxJR",
        "outputId": "9aef5dd5-894f-4f56-c4c0-f19aac2c84eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset converted and saved as ./datasets/emotions_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "# Define the path to save the CSV\n",
        "csv_file_path = './datasets/emotions_dataset.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Dataset converted and saved as {csv_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4yYNBWCSxJS",
        "outputId": "b4f56798-7209-4aba-e095-e351b2394589"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Emotion\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JWGqEBASxJT",
        "outputId": "31a822d4-e29d-4c1e-fd93-23dac65efd5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text       0\n",
              "Emotion    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p92h1Ok1SxJU",
        "outputId": "bbcf4bf6-4c8c-4541-8e04-e1ebb9619b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                    Text   Emotion\n",
            "5067   i feel on the verge of tears from weariness i ...       joy\n",
            "6133               i still feel a craving for sweet food      love\n",
            "6563   i tend to stop breathing when i m feeling stre...     anger\n",
            "7623   i was intensely conscious of how much cash i h...   sadness\n",
            "7685   im still not sure why reilly feels the need to...  surprise\n",
            "8246   i am not amazing or great at photography but i...      love\n",
            "9596   ive also made it with both sugar measurements ...       joy\n",
            "9687   i had to choose the sleek and smoother feel of...       joy\n",
            "9769   i often find myself feeling assaulted by a mul...   sadness\n",
            "9786        i feel im being generous with that statement       joy\n",
            "10117  i feel pretty tortured because i work a job an...      fear\n",
            "10581                       i feel most passionate about       joy\n",
            "11273  i was so stubborn and that it took you getting...       joy\n",
            "11354  i write these words i feel sweet baby kicks fr...      love\n",
            "11525  i feel a remembrance of the strange by justin ...      fear\n",
            "11823  i have chose for myself that makes me feel ama...       joy\n",
            "12441                   i still feel completely accepted      love\n",
            "12562                           i feel so weird about it  surprise\n",
            "12892  i cant escape the tears of sadness and just tr...       joy\n",
            "13236   i feel like a tortured artist when i talk to her     anger\n",
            "13846  i feel more adventurous willing to take risks ...       joy\n",
            "13880  i feel like i am very passionate about youtube...      love\n",
            "14107                             i feel kind of strange  surprise\n",
            "14314    i could feel myself hit this strange foggy wall  surprise\n",
            "14634  i feel pretty weird blogging about deodorant b...      fear\n",
            "14926  i resorted to yesterday the post peak day of i...      fear\n",
            "15315  i will feel as though i am accepted by as well...       joy\n",
            "15329  i shy away from songs that talk about how i fe...       joy\n",
            "15572  i bet taylor swift basks in the knowledge that...     anger\n",
            "15705  i began to feel accepted by gaia on her own terms       joy\n",
            "15876  i was sitting in the corner stewing in my own ...     anger\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicates in the 'Text' column\n",
        "duplicates_text = df[df['Text'].duplicated()]\n",
        "\n",
        "# Display the duplicated text rows\n",
        "print(duplicates_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi2T4ErzSxJV",
        "outputId": "305f7edd-09aa-4243-fe48-62dbf2876dce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "joy         5362\n",
              "sadness     4666\n",
              "anger       2159\n",
              "fear        1937\n",
              "love        1304\n",
              "surprise     572\n",
              "Name: Emotion, dtype: int64"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK4h-k7lSxJW",
        "outputId": "083b42b4-db81-44a7-a8fe-45d2553daf2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16000 entries, 0 to 15999\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Text     16000 non-null  object\n",
            " 1   Emotion  16000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 250.1+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LekXBVnFSxJW",
        "outputId": "eab597b7-c2c1-4b09-8e56-eff2b9e8fe8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbcHfV81SxJX"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate rows\n",
        "df.drop_duplicates(subset=['Text'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3skjuXUASxJX",
        "outputId": "281220f5-e337-43b5-9fd9-a39534b2f3ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OoaB92VSxJX",
        "outputId": "0ad2dc5b-4b6a-488f-9eee-abefff1b1a3a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "joy         5350\n",
            "sadness     4664\n",
            "anger       2155\n",
            "fear        1933\n",
            "love        1299\n",
            "surprise     568\n",
            "Name: Emotion, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Plot class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Emotion', data=df)\n",
        "plt.title('Emotion Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Check the count of each class\n",
        "print(df['Emotion'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtBsK6KgSxJY",
        "outputId": "01f7cdc4-555d-4ef9-c903-8b4ac6d84347"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/sehar/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Text Preprocessing\n",
        "The text data needs to be tokenized and preprocessed before it can be used our encoder.\n",
        "\n",
        "Lowercasing: Convert the text to lowercase for uniformity.\n",
        "Removing punctuation/numbers: Remove unnecessary characters.\n",
        "Removing stopwords (optional): Remove common words (e.g., 'the', 'is', 'in').\n",
        "Tokenization: Split text into words or subwords.\n",
        "'''\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK packages\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function for text cleaning\n",
        "def clean_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) #regular expression ([^a-z\\s]) removes everything except lowercase letters (a-z) and spaces (\\s)\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function\n",
        "df['cleaned_text'] = df['Text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEGu0xe5SxJY",
        "outputId": "a7e63f9c-7b8d-4c12-e753-3ffe17775309"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "      <td>didnt feel humiliated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>go feeling hopeless damned hopeful around some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "      <td>im grabbing minute post feel greedy wrong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "      <td>feeling grouchy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Emotion  \\\n",
              "0                            i didnt feel humiliated  sadness   \n",
              "1  i can go from feeling so hopeless to so damned...  sadness   \n",
              "2   im grabbing a minute to post i feel greedy wrong    anger   \n",
              "3  i am ever feeling nostalgic about the fireplac...     love   \n",
              "4                               i am feeling grouchy    anger   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0                              didnt feel humiliated  \n",
              "1  go feeling hopeless damned hopeful around some...  \n",
              "2          im grabbing minute post feel greedy wrong  \n",
              "3  ever feeling nostalgic fireplace know still pr...  \n",
              "4                                    feeling grouchy  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puYwB_8QSxJZ",
        "outputId": "a953b20a-bacc-46c3-d3f2-a3cff8d0cc38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized Input IDs: tensor([[  101,  2134,  2102,  ...,     0,     0,     0],\n",
            "        [  101,  2175,  3110,  ...,     0,     0,     0],\n",
            "        [  101, 10047,  9775,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2514,  2844,  ...,     0,     0,     0],\n",
            "        [  101,  2514,  2066,  ...,     0,     0,     0],\n",
            "        [  101,  2113,  2843,  ...,     0,     0,     0]])\n",
            "Attention Mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "#tokenization\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Load pre-trained tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# Tokenize the texts using the BERT tokenizer\n",
        "encoded_inputs = tokenizer(list(df.cleaned_text), padding=True, truncation=True, max_length=128,return_tensors=\"pt\")\n",
        "\n",
        "# Check the tokenized input\n",
        "print(\"Tokenized Input IDs:\", encoded_inputs[\"input_ids\"])\n",
        "print(\"Attention Mask:\", encoded_inputs[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UnknbJLSxJZ"
      },
      "outputs": [],
      "source": [
        "# Map emotions to numerical labels\n",
        "label_map = {\"joy\": 0, \"sadness\": 1, \"anger\": 2, \"fear\": 3, \"love\": 4, \"surprise\": 5}\n",
        "df['Emotion'] = df['Emotion'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bycrM5OSxJa",
        "outputId": "422f69e1-7853-4a0f-f866-c2550af7eab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels:\n",
            " tensor([1, 1, 2,  ..., 0, 2, 1])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nInput IDs: These are the tokenized and numerical representations of the text.\\nAttention Mask: Indicates which tokens are real (1) and which are padding (0).\\nLabels: Numerical values corresponding to emotion labels.\\n'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = torch.tensor(df['Emotion'].values)\n",
        "print(\"Labels:\\n\", labels)\n",
        "\n",
        "'''\n",
        "Input IDs: These are the tokenized and numerical representations of the text.\n",
        "Attention Mask: Indicates which tokens are real (1) and which are padding (0).\n",
        "Labels: Numerical values corresponding to emotion labels.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3DX1Ob4SxJa",
        "outputId": "09c41bf8-aebc-4efc-a7dd-1145be085623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 15969 entries, 0 to 15999\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Text          15969 non-null  object\n",
            " 1   Emotion       15969 non-null  int64 \n",
            " 2   cleaned_text  15969 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK3lrWeqSxJb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Create TensorDataset from tokenized inputs and emotion labels\n",
        "emotion_dataset = TensorDataset(\n",
        "    encoded_inputs[\"input_ids\"],  # Tokenized inputs\n",
        "    torch.tensor(df[\"Emotion\"].values, dtype=torch.long)  # Emotion labels as tensor\n",
        ")\n",
        "\n",
        "# DataLoader for batching\n",
        "emotion_dataloader = DataLoader(emotion_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOhHyr8NSxJb",
        "outputId": "6cb0eed9-2937-465b-c500-438eb26175e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs Shape: torch.Size([15969, 72])\n",
            "Emotion Labels Shape: (15969,)\n"
          ]
        }
      ],
      "source": [
        "# Check the shapes\n",
        "print(\"Input IDs Shape:\", encoded_inputs[\"input_ids\"].shape)  # Should return (num_samples, sequence_length)\n",
        "print(\"Emotion Labels Shape:\", df[\"Emotion\"].values.shape)   # Should return (num_samples,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXPflbdzSxJb",
        "outputId": "5fa42ee2-61cd-444a-fc17-1de8c7118dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Input Shape: torch.Size([32, 72])\n",
            "Batch Label Shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# Check DataLoader\n",
        "for batch in emotion_dataloader:\n",
        "    print(\"Batch Input Shape:\", batch[0].shape)  # Should return (batch_size, sequence_length)\n",
        "    print(\"Batch Label Shape:\", batch[1].shape)  # Should return (batch_size,)\n",
        "    break  # Test one batch only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn5JLxKMSxJc"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "vocab_size = len(tokenizer.get_vocab())  # Size of tokenizer vocab\n",
        "n_embd = 128  # Embedding dimension\n",
        "block_size = encoded_inputs[\"input_ids\"].shape[1]  # Maximum sequence length\n",
        "n_head = 4  # Number of attention heads\n",
        "n_layer = 2  # Number of transformer layers\n",
        "n_emotions = len(label_map)  # Number of emotion classes\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape  # Batch size, Sequence length, Embedding size\n",
        "        k = self.key(x) # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        v = self.value(x)\n",
        "        print(f\"Input Shape: {x.shape}\")\n",
        "        print(f\"Key Shape: {k.shape}\")\n",
        "        print(f\"Query Shape: {q.shape}\")\n",
        "        print(f\"Value Shape: {v.shape}\")\n",
        "\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5  # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "        '''\n",
        "        Purpose: Computes attention scores and aggregates values using these scores.\n",
        "        Output: A tensor of shape (B, T, head_size).\n",
        "        The output out is the attention output, which contains the weighted representation of the sequence after attending to all tokens.\n",
        "        '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BmodR60SxJc"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch\n",
        "\n",
        "# # Example inputs\n",
        "# B, T, C = 2, 5, 8  # Batch size, Sequence length, Embedding size\n",
        "# head_size = 4\n",
        "# x = torch.rand(B, T, C)\n",
        "# dropout = 0.1\n",
        "\n",
        "# # Initialize single head\n",
        "# single_head = Head(head_size=head_size, n_embd=C)\n",
        "# output = single_head(x)\n",
        "# print(\"Input Shape:\", x.shape)  # Should be (2, 5, 8)\n",
        "# print(\"Output:\", output)  # Should be (2, 5, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHU6hJUASxJd"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class MultiHeadAttention(nn.Module):\n",
        "#     #Purpose: Combines multiple attention heads for parallel processing\n",
        "#     def __init__(self, n_embd,num_heads, head_size):\n",
        "#         super().__init__()\n",
        "#         self.heads = nn.ModuleList([Head(head_size,n_embd = C) for _ in range(num_heads)])\n",
        "#         self.proj = nn.Linear(n_embd, n_embd)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#     '''\n",
        "#     num_heads: Number of parallel attention heads.\n",
        "#     head_size: Dimension of each head.\n",
        "#     proj: Projects concatenated outputs of all heads back to the original embedding dimension.\n",
        "#     '''\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = torch.cat([h(x) for h in self.heads], dim=-1)  # Concatenate head outputs\n",
        "#         out = self.proj(out)  # Final projection\n",
        "#         out = self.dropout(out)\n",
        "#         return out\n",
        "\n",
        "#     '''\n",
        "#     Purpose: Aggregates outputs of all attention heads.\n",
        "#     Output: A tensor of shape (B, T, n_embd).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVlk449GSxJd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = embedding_dim // num_heads\n",
        "        assert embedding_dim % num_heads == 0, \"embedding_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.query = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.key = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.value = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.proj = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x).view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
        "        k = self.key(x).view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
        "        v = self.value(x).view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "        # Attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_size ** 0.5)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # Apply attention to values\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.proj(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cJSQvJmSxJd"
      },
      "outputs": [],
      "source": [
        "# n_embd = C  # Embedding dimension matches input\n",
        "# num_heads = 2  # Number of attention heads\n",
        "# head_size = n_embd // num_heads  # Dimension per head\n",
        "# # Initialize MultiHeadAttention\n",
        "# multihead_attn = MultiHeadAttention(n_embd, num_heads, head_size)\n",
        "# out = multihead_attn(x)\n",
        "# print(\"Input Shape:\", x.shape)  # Expected: (2, 5, 8)\n",
        "# print(\"Output:\", out)  # Expected: (2, 5, 8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14_mCZ0LSxJe",
        "outputId": "985db4ce-961b-41d5-fd73-be794b0a5673"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nnn.Linear(n_embd, 4 * n_embd): Expands the input embedding dimension to increase model capacity.\\nnn.ReLU(): Applies a non-linear activation function.\\nnn.Linear(4 * n_embd, n_embd): Projects the expanded dimension back to the original size.\\nnn.Dropout(0.1): Prevents overfitting by randomly zeroing out some outputs.\\nExample Input and Output:\\nInput: x with shape (B, T, n_embd).\\nOutput: x with the same shape (B, T, n_embd).\\n'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "The feedforward network provides non-linear transformations for each token embedding independently,\n",
        "giving the model additional representational power.\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\" A simple feedforward neural network used within each transformer block. \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),  # Expand embedding dimension\n",
        "            nn.ReLU(),                      # Activation\n",
        "            nn.Linear(4 * n_embd, n_embd),  # Project back to original size\n",
        "            nn.Dropout(0.2),                # Add regularization\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)  # Apply feedforward network\n",
        "\n",
        "'''\n",
        "nn.Linear(n_embd, 4 * n_embd): Expands the input embedding dimension to increase model capacity.\n",
        "nn.ReLU(): Applies a non-linear activation function.\n",
        "nn.Linear(4 * n_embd, n_embd): Projects the expanded dimension back to the original size.\n",
        "nn.Dropout(0.1): Prevents overfitting by randomly zeroing out some outputs.\n",
        "Example Input and Output:\n",
        "Input: x with shape (B, T, n_embd).\n",
        "Output: x with the same shape (B, T, n_embd).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2euGW-x1SxJe"
      },
      "outputs": [],
      "source": [
        "# feedforward = FeedForward(n_embd)\n",
        "\n",
        "# # Forward pass\n",
        "# output = feedforward(out)\n",
        "\n",
        "# # Print the output shape and values\n",
        "# print(\"Input Shape:\", out.shape)  # Should be [2, 5, 8]\n",
        "# print(\"Output Shape:\", output.shape)  # Should be [2, 5, 8]\n",
        "# print(\"Output Tensor:\\n\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_o-CuefSxJf"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: self-attention followed by feedforward computation. \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        #head_size = n_embd // n_head  # Divide embedding across heads\n",
        "        self.sa = MultiHeadSelfAttention(n_embd,n_head)  # Self-attention\n",
        "        self.ffwd = FeedForward(n_embd)  # Feedforward network\n",
        "        self.ln1 = nn.LayerNorm(n_embd)  # Layer norm for attention\n",
        "        self.ln2 = nn.LayerNorm(n_embd)  # Layer norm for feedforward\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply self-attention with residual connection\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        # Apply feedforward with residual connection\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKtolTKWSxJf",
        "outputId": "ad34b91c-6638-4364-96f7-273114b3ed6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head Size: 32\n"
          ]
        }
      ],
      "source": [
        "head_size = n_embd // n_head  # Should be 32 if n_embd=128 and n_head=4\n",
        "print(f\"Head Size: {head_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDYl-ZSVSxJf"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# # Initialize the Block with n_embd=8 (embedding size) and n_head=2 (number of attention heads)\n",
        "# block = Block(n_embd, num_heads)\n",
        "\n",
        "# # Pass the test input through the block\n",
        "# output = block(output)\n",
        "\n",
        "# # Print the output shape to check\n",
        "# print(\"Output:\", output)  # Should be [batch_size, sequence_length, embedding_size]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72OZnIDXSxJg",
        "outputId": "ff9535ff-9f1a-4d8a-c457-2b96378d584b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\neach block includes:\\n\\nMulti-Head Attention (captures relationships between tokens).\\nFeed-Forward Network (adds non-linearity and depth).\\nResidual Connections + LayerNorm (improves gradient flow and stability).\\n'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# step 1: build the encoder\n",
        "'''\n",
        "token ids --> embedding vectors --> self-attention --> feedforward layers --> context vectors\n",
        "context vectors --> classification head --> output logits\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class unified_encoder(nn.Module):\n",
        "    def __init__(self,vocab_size,n_embd,block_size,n_head,n_layer):\n",
        "        super().__init__()\n",
        "        self.token_embedding=nn.Embedding(vocab_size,n_embd)\n",
        "        self.position_embedding=nn.Embedding(block_size,n_embd)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(n_embd, n_head=n_head) for _ in range(n_layer)]  # Stack of blocks\n",
        "        )\n",
        "        self.ln_f = nn.LayerNorm(n_embd)  # Final Layer Norm\n",
        "\n",
        "    def forward(self,idx):\n",
        "        B,T=idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding(torch.arange(T, device=idx.device)) # (T,C)\n",
        "        x= tok_emb + pos_emb  # Add embeddings\n",
        "\n",
        "        # Pass through Transformer Blocks\n",
        "        x = self.blocks(x)  # (B, T, n_embd)\n",
        "\n",
        "        # Apply Final Layer Normalization\n",
        "        x = self.ln_f(x)  # (B, T, n_embd)\n",
        "\n",
        "        return x  # Contextualized representations\n",
        "\n",
        "'''\n",
        "each block includes:\n",
        "\n",
        "Multi-Head Attention (captures relationships between tokens).\n",
        "Feed-Forward Network (adds non-linearity and depth).\n",
        "Residual Connections + LayerNorm (improves gradient flow and stability).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW6gYgVgSxJg",
        "outputId": "69c20e6c-6bbc-4d91-9dc7-b8cd7207c7a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nOnce we have the encoder, the context vectors generated by this encoder will be used:\\n\\nTo classify the emotion (using a classifier head).\\nTo pass into the decoder (for generating responses).\\n'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Once we have the encoder, the context vectors generated by this encoder will be used:\n",
        "\n",
        "To classify the emotion (using a classifier head).\n",
        "To pass into the decoder (for generating responses).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D7F3QsuSxJh"
      },
      "outputs": [],
      "source": [
        "#Step 2: Add Classifier Head for Emotion Detection\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, n_embd, n_emotions):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(n_embd, n_emotions)\n",
        "\n",
        "    def forward(self, context_vector):\n",
        "        # Assume context_vector is (B, T, n_embd), take mean pooling\n",
        "        pooled = context_vector.mean(dim=1)  # (B, n_embd)\n",
        "        logits = self.linear(pooled)  # (B, n_emotions)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ioesd9aGSxJh"
      },
      "outputs": [],
      "source": [
        "#Step 3: Train Encoder + Classifier on Emotion Dataset\n",
        "# Combine Encoder and Classifier\n",
        "class EmotionDetectionModel(nn.Module):\n",
        "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer, n_emotions):\n",
        "        super().__init__()\n",
        "        self.encoder = unified_encoder(vocab_size, n_embd, block_size, n_head, n_layer)\n",
        "        self.classifier = EmotionClassifier(n_embd, n_emotions)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        context_vector = self.encoder(idx)  # Get context vector\n",
        "        logits = self.classifier(context_vector)  # Predict emotions\n",
        "        return logits\n",
        "\n",
        "# Initialize model\n",
        "model = EmotionDetectionModel(vocab_size, n_embd, block_size, n_head, n_layer, n_emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QooNK_5SxJh",
        "outputId": "7fb9a616-c5fc-4932-a610-ac48fe86b891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 2,  ..., 0, 2, 1])\n",
            "[0.49747664 0.57064751 1.2350348  1.37687532 2.04888376 4.68573944]\n",
            "tensor([0.4975, 0.5706, 1.2350, 1.3769, 2.0489, 4.6857])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "labels = torch.tensor(df['Emotion'].values, dtype=torch.long)\n",
        "print(labels)\n",
        "np_labels=labels.numpy()\n",
        "unique_class=np.unique(labels)\n",
        "\n",
        "# Compute class weights using sklearn\n",
        "class_weights = compute_class_weight('balanced', classes=unique_class, y=np_labels)\n",
        "print(class_weights)\n",
        "\n",
        "# Convert class weights to a tensor\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "print(class_weights_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPcX9y3lSxJ3",
        "outputId": "b834bb01-04e5-4301-9d19-57e402c26a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  101  2134  2102 ...     0     0     0]\n",
            " [  101  2175  3110 ...     0     0     0]\n",
            " [  101 10047  9775 ...     0     0     0]\n",
            " ...\n",
            " [  101  2822  2745 ...     0     0     0]\n",
            " [  101  2514  6309 ...     0     0     0]\n",
            " [  101  3334  3153 ...     0     0     0]] [1 1 2 ... 5 5 5]\n",
            "tensor([[  101,  2134,  2102,  ...,     0,     0,     0],\n",
            "        [  101,  2175,  3110,  ...,     0,     0,     0],\n",
            "        [  101, 10047,  9775,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2822,  2745,  ...,     0,     0,     0],\n",
            "        [  101,  2514,  6309,  ...,     0,     0,     0],\n",
            "        [  101,  3334,  3153,  ...,     0,     0,     0]]) tensor([1, 1, 2,  ..., 5, 5, 5])\n",
            "Train inputs shape: torch.Size([25680, 72])\n",
            "Train labels shape: torch.Size([25680])\n",
            "Test inputs shape: torch.Size([6420, 72])\n",
            "Test labels shape: torch.Size([6420])\n",
            "Epoch 1, Train Loss: 1.6734, Val Loss: 1.5876, Accuracy: 0.3075\n",
            "Epoch 2, Train Loss: 1.5582, Val Loss: 1.5448, Accuracy: 0.3388\n",
            "Epoch 3, Train Loss: 1.4761, Val Loss: 1.4679, Accuracy: 0.3768\n",
            "Epoch 4, Train Loss: 1.3585, Val Loss: 1.3794, Accuracy: 0.4277\n",
            "Epoch 5, Train Loss: 1.2434, Val Loss: 1.3004, Accuracy: 0.4550\n",
            "Epoch 6, Train Loss: 1.1465, Val Loss: 1.2532, Accuracy: 0.4891\n",
            "Epoch 7, Train Loss: 1.0590, Val Loss: 1.2003, Accuracy: 0.5042\n",
            "Epoch 8, Train Loss: 0.9869, Val Loss: 1.1656, Accuracy: 0.5260\n",
            "Epoch 9, Train Loss: 0.9278, Val Loss: 1.1542, Accuracy: 0.5308\n",
            "Epoch 10, Train Loss: 0.8743, Val Loss: 1.1348, Accuracy: 0.5444\n",
            "Epoch 11, Train Loss: 0.8288, Val Loss: 1.1642, Accuracy: 0.5433\n",
            "Epoch 12, Train Loss: 0.7841, Val Loss: 1.1646, Accuracy: 0.5498\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-900f2ba6099c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/schittVision/.venv/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/schittVision/.venv/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/schittVision/.venv/lib/python3.6/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                     eps=group['eps'])\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/schittVision/.venv/lib/python3.6/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Prepare the data\n",
        "input_ids = encoded_inputs[\"input_ids\"]\n",
        "labels = torch.tensor(df['Emotion'].values, dtype=torch.long)\n",
        "\n",
        "# Oversample minority classes using SMOTE\n",
        "# Apply SMOTE to oversample the minority classes\n",
        "smote = SMOTE(random_state=42)\n",
        "input_ids_resampled, labels_resampled = smote.fit_resample(input_ids.numpy(), labels.numpy())\n",
        "print(\"input ids resampled\",input_ids_resampled.shape)\n",
        "print(\"labels resampled\",labels_resampled.shape)\n",
        "\n",
        "# Convert the resampled data back to PyTorch tensors\n",
        "input_ids_resampled = torch.tensor(input_ids_resampled.round(), dtype=torch.long)  # Ensure 2D tensor\n",
        "labels_resampled = torch.tensor(labels_resampled, dtype=torch.long)     # Ensure 1D tensor\n",
        "print(\"input ids resampled tesnor\",input_ids_resampled,\"labels resampled tensor\",labels_resampled)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "    input_ids_resampled, labels_resampled, test_size=0.2, random_state=42, stratify=labels_resampled, shuffle=True\n",
        ")\n",
        "print(\"Train inputs shape:\", train_inputs.shape)  # Should be (num_samples, feature_dim)\n",
        "print(\"Train labels shape:\", train_labels.shape)  # Should be (num_samples,)\n",
        "print(\"Test inputs shape:\", test_inputs.shape)    # Should be (num_samples, feature_dim)\n",
        "print(\"Test labels shape:\", test_labels.shape)    # Should be (num_samples,)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "test_dataset = TensorDataset(test_inputs, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Compute class weights\n",
        "unique_classes = np.unique(train_labels.numpy())\n",
        "class_weights = compute_class_weight('balanced', classes=unique_classes, y=train_labels.numpy())\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# 2. Define Model, Loss, Optimizer\n",
        "model = EmotionDetectionModel(vocab_size, n_embd, block_size, n_head, n_layer, n_emotions)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,weight_decay=1e-2)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10\n",
        "# Initialize lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss for the epoch\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(train_losses)\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct_preds = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, labels = batch\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())  # Collect true labels\n",
        "            all_preds.extend(preds.cpu().numpy())    # Collect predictions\n",
        "\n",
        "    # Calculate average validation loss and accuracy for the epoch\n",
        "    avg_val_loss = total_val_loss / len(test_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(val_losses)\n",
        "    val_accuracy = correct_preds / total_samples\n",
        "\n",
        "    # Print epoch metrics\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "emotion_classes = ['joy', 'sadness', 'anger', 'fear', 'love', 'surprise']  # Replace with your actual emotion names\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=emotion_classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65srkQABSxJ4",
        "outputId": "82e1cefa-8d4c-4ca7-dfa4-984ad39f2ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Inputs Shape: torch.Size([12775, 72])\n",
            "Epoch 1/3, Loss: 0.6975478515774012\n",
            "Epoch 2/3, Loss: 0.5851915260404348\n",
            "Epoch 3/3, Loss: 0.5552237077057361\n"
          ]
        }
      ],
      "source": [
        "#Step 4: Train the Model\n",
        "import torch.optim as optim\n",
        "\n",
        "# Prepare data\n",
        "input_ids = encoded_inputs[\"input_ids\"]\n",
        "labels = torch.tensor(df['Emotion'].values, dtype=torch.long)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform a random split\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "    input_ids, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "\n",
        "print(f\"Train Inputs Shape: {train_inputs.shape}\")\n",
        "# print(f\"Train Inputs Shape Before Model: {train_inputs.unsqueeze(0).shape}\")\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Create TensorDataset and DataLoader\n",
        "train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_inputs, batch_labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch_inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, batch_labels)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4Np2FAjSxJ5",
        "outputId": "415a317e-375a-43ef-ebff-a4e877a5a60c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Fold 1, Val Loss: 1.7936, Accuracy: 0.3362\n",
            "Epoch 2, Fold 1, Val Loss: 1.7936, Accuracy: 0.3362\n",
            "Epoch 3, Fold 1, Val Loss: 1.7936, Accuracy: 0.3362\n",
            "Epoch 1, Fold 2, Val Loss: 1.8192, Accuracy: 0.1374\n",
            "Epoch 2, Fold 2, Val Loss: 1.8192, Accuracy: 0.1374\n",
            "Epoch 3, Fold 2, Val Loss: 1.8192, Accuracy: 0.1374\n",
            "Epoch 1, Fold 3, Val Loss: 1.8134, Accuracy: 0.1374\n",
            "Epoch 2, Fold 3, Val Loss: 1.8134, Accuracy: 0.1374\n",
            "Epoch 3, Fold 3, Val Loss: 1.8134, Accuracy: 0.1374\n",
            "Epoch 1, Fold 4, Val Loss: 1.8244, Accuracy: 0.3382\n",
            "Epoch 2, Fold 4, Val Loss: 1.8244, Accuracy: 0.3382\n",
            "Epoch 3, Fold 4, Val Loss: 1.8244, Accuracy: 0.3382\n",
            "Epoch 1, Fold 5, Val Loss: 1.7915, Accuracy: 0.1632\n",
            "Epoch 2, Fold 5, Val Loss: 1.7915, Accuracy: 0.1632\n",
            "Epoch 3, Fold 5, Val Loss: 1.7915, Accuracy: 0.1632\n",
            "Test Loss: 1.1443, Test Accuracy: 0.4371\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter()\n",
        "\n",
        "# 1. Prepare the data\n",
        "input_ids = encoded_inputs[\"input_ids\"]\n",
        "labels = torch.tensor(df['Emotion'].values, dtype=torch.long)\n",
        "\n",
        "np_labels=labels.numpy()\n",
        "unique_class=np.unique(labels)\n",
        "\n",
        "# Compute class weights using sklearn\n",
        "class_weights = compute_class_weight('balanced', classes=unique_class, y=np_labels)\n",
        "#print(class_weights)\n",
        "\n",
        "# Convert class weights to a tensor\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "#print(class_weights_tensor)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "    input_ids, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Test set for final evaluation\n",
        "test_dataset = TensorDataset(test_inputs, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 2. Perform k-fold cross-validation on the training set\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_inputs,train_labels)):\n",
        "    # Split into fold-specific train and validation sets\n",
        "    fold_train_inputs = train_inputs[train_idx]\n",
        "    fold_train_labels = train_labels[train_idx]\n",
        "    fold_val_inputs = train_inputs[val_idx]\n",
        "    fold_val_labels = train_labels[val_idx]\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_dataset = TensorDataset(fold_train_inputs, fold_train_labels)\n",
        "    val_dataset = TensorDataset(fold_val_inputs, fold_val_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Initialize model, optimizer, and loss function\n",
        "    # Replace \"YourModel()\" with your actual model class\n",
        "    model = EmotionDetectionModel(vocab_size, n_embd, block_size, n_head, n_layer, n_emotions)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience, counter = 3, 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            inputs, labels = batch\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                inputs, labels = batch\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, labels)\n",
        "                val_loss += loss.item()\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        val_accuracy = correct / total\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            counter = 0\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "        print(f\"Epoch {epoch+1}, Fold {fold+1}, Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "        # Example: Log validation loss and accuracy\n",
        "        # writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
        "        # writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n",
        "\n",
        "# 3. Test the model after k-fold cross-validation\n",
        "# Train the final model on the entire training set (all folds combined)\n",
        "final_train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "final_train_loader = DataLoader(final_train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Reinitialize the model\n",
        "model = EmotionDetectionModel(vocab_size, n_embd, block_size, n_head, n_layer, n_emotions)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Train on the entire training set\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in final_train_loader:\n",
        "        inputs, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate on the test set\n",
        "model.eval()\n",
        "test_loss, correct, total = 0, 0, 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        logits = model(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqlYyUiSxJ6"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"emotion_detection_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOH19B7xSxJ6",
        "outputId": "9d25eed8-7bf9-4cd4-c8d3-63ebd79797bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 86.63%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.88      1029\n",
            "           1       0.93      0.87      0.90       970\n",
            "           2       0.87      0.85      0.86       399\n",
            "           3       0.84      0.88      0.86       385\n",
            "           4       0.77      0.80      0.78       292\n",
            "           5       0.81      0.71      0.76       119\n",
            "\n",
            "    accuracy                           0.87      3194\n",
            "   macro avg       0.85      0.84      0.84      3194\n",
            "weighted avg       0.87      0.87      0.87      3194\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation function\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def evaluate_model(model, test_inputs, test_labels):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        logits = model(test_inputs)  # Add batch dimension if needed\n",
        "        predictions = torch.argmax(logits, dim=-1)  # Get predicted labels\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(test_labels.numpy(), predictions.numpy())\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(test_labels.numpy(), predictions.numpy(), zero_division=0))\n",
        "\n",
        "# Call the evaluation function\n",
        "evaluate_model(model, test_inputs, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EqvYqMrSxJ6",
        "outputId": "421503c1-b377-427e-967a-b9e93a4b315e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: I feel so happy and excited today!\n",
            "Predicted Emotion: joy\n",
            "\n",
            "Text: are you for real?.\n",
            "Predicted Emotion: joy\n",
            "\n",
            "Text: I feel humiliated\n",
            "Predicted Emotion: sadness\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Unseen text data\n",
        "unseen_texts = [\n",
        "    \"I feel so happy and excited today!\",\n",
        "    \"are you for real?.\",\n",
        "    \"I feel humiliated\",\n",
        "]\n",
        "\n",
        "# Tokenize unseen data\n",
        "unseen_inputs = tokenizer(\n",
        "    unseen_texts,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=block_size,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    logits = model(unseen_inputs[\"input_ids\"])\n",
        "    predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# Map predicted labels back to emotions\n",
        "predicted_emotions = [list(label_map.keys())[label] for label in predicted_labels.tolist()]\n",
        "\n",
        "# Display results\n",
        "for text, emotion in zip(unseen_texts, predicted_emotions):\n",
        "    print(f\"Text: {text}\\nPredicted Emotion: {emotion}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEPY20TKSxJ7"
      },
      "outputs": [],
      "source": [
        "#Step 5: Generate Contextual Embeddings for Transcript\n",
        "model.eval()\n",
        "transcript_context_vectors = model.encoder(encoded_inputs_transcript[\"input_ids\"])\n",
        "predicted_emotions = torch.argmax(model.classifier(transcript_context_vectors), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3pEreOISxJ7"
      },
      "outputs": [],
      "source": [
        "#Step 6: Combine Context Vector and Emotion\n",
        "# Convert emotion labels to embeddings\n",
        "emotion_embeddings = nn.Embedding(n_emotions, n_embd)(predicted_emotions)\n",
        "\n",
        "# Combine\n",
        "combined_context = torch.cat((transcript_context_vectors, emotion_embeddings.unsqueeze(1)), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj3cCN3jSxJ7",
        "outputId": "a1e77778-52dc-4a8b-ae58-0104d013b25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.3994,  0.5665,  0.3013,  0.0202, -0.5509, -0.0942,  1.8713,\n",
            "           0.3024, -1.7799, -1.7184,  1.7541,  0.1235,  0.5850, -3.5811,\n",
            "          -1.0096,  0.4357, -0.3381,  0.4427, -2.4342, -0.0204, -0.4430,\n",
            "           0.0122, -0.7444, -0.3003, -0.1600,  0.0199, -1.1334,  2.0142,\n",
            "           3.6400,  2.4960]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# vocab_size = 30522  # BERT tokenizer vocab size\n",
        "# n_embd = 128\n",
        "# block_size = 512\n",
        "# n_head = 4\n",
        "# n_layer = 2\n",
        "\n",
        "# encoder = unified_encoder(vocab_size, n_embd, block_size, n_head, n_layer)\n",
        "\n",
        "# # Example input: batch size = 2, sequence length = 5\n",
        "# idx = torch.tensor([[101, 2054, 2003, 2023, 102], [101, 2129, 2024, 2017, 102]])\n",
        "# context_vector = encoder(idx)\n",
        "# print(context_vector.shape)  # Output: (2, 5, 128)\n",
        "# '''\n",
        "# m=unified_encoder(vocab_size=65,n_embd=30,block_size=4)\n",
        "# print(m.forward(idx=torch.zeros(1,1,dtype=torch.long)))\n",
        "# '''"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "1b031f88d9e7d998b303763756b59f5e279d46025b2b69c22eea4c0556414731"
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}